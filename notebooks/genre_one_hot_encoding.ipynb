{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genre_one_hot_encoding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaUgDj1d1I4I"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPX4M9egaz5_"
      },
      "source": [
        "# Calculate Genre one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYsaYJMUuqtK"
      },
      "source": [
        "# helper functions for Genre one hot encoding\n",
        "\n",
        "def preprocess_genre_data(df, keep_name_col=False):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  df = df[[NAME_COL, GENRE_COL]].dropna()\n",
        "  formatted_genre_col = GENRE_COL+'_formatted'\n",
        "  df[formatted_genre_col] = df[GENRE_COL].apply(lambda x: x.replace(\"|\", \" \"))\n",
        "  df.drop(GENRE_COL, axis=1, inplace=True)\n",
        "  df.rename(columns={formatted_genre_col: GENRE_COL}, inplace=True)\n",
        "  if keep_name_col:\n",
        "    return df\n",
        "  else:\n",
        "    return df[formatted_genre_col].values\n",
        "\n",
        "def load_genre_training_data(training_data_path, keep_name_col=False):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(training_data_path, sep='\\t')\n",
        "  return preprocess_genre_data(df, keep_name_col)\n",
        "\n",
        "def fit_genre_vectorizer_layer(layer, training_data_path):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  training_data = load_genre_training_data(training_data_path)\n",
        "  layer.adapt(training_data)\n",
        "  return layer, layer.get_vocabulary()\n",
        "\n",
        "def load_genre_vectorizer_layer(layer, vocab):\n",
        "  \"\"\"\n",
        "  Sets `vocab` as the vocabulary of `layer`.\n",
        "  \n",
        "  :param layer: tf.keras.layers.experimental.preprocessing.TextVectorization\n",
        "  :param vocab: List of strings (vocabulary elements)\n",
        "  \n",
        "  :return tf.keras.layers.experimental.preprocessing.TextVectorization \n",
        "  \"\"\"\n",
        "  layer.set_vocabulary(vocab)\n",
        "  \n",
        "def read_genre_vocab(vocab_path):\n",
        "  \"\"\"\n",
        "  Reads vocabulary for genre one hot encoder from CSV file. \n",
        "  CSV file must have no header.\n",
        "  Each element of vocabulary must be in its separate lines.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    vocab = pd.read_csv(vocab_path, header=None)[0].values.tolist()\n",
        "  except ValueError:\n",
        "      print(\"\"\"VOCAB_PATH not found, please retrain the genre model with \n",
        "      get_genre_one_hot_encoder_model(train=True, overwrite_vocab=True)\"\"\")\n",
        "  return vocab[1:]  # index 0 is OOV token\n",
        "\n",
        "def get_genre_one_hot_encoder_model(train=False, write_vocab=False):\n",
        "  \"\"\"\n",
        "  Returns Genre one hot encoder model. \n",
        "  If `train` is True, fits the genre vectorizer layer to training data.\n",
        "  If `train` is False, loads pre-fitted genre vectorizer layer.\n",
        "  \"\"\"\n",
        "  textVectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(output_mode='binary')\n",
        "  \n",
        "  if train:\n",
        "    textVectorizer, vocab = fit_genre_vectorizer_layer(textVectorizer, GENRE_TRAINING_DATA_PATH)\n",
        "    if write_vocab:\n",
        "      pd.DataFrame(vocab).to_csv(VOCAB_PATH, index=False, header=False)\n",
        "  else:\n",
        "    vocab = read_genre_vocab(VOCAB_PATH)\n",
        "    load_genre_vectorizer_layer(textVectorizer, vocab)\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "  model.add(textVectorizer)\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33QZ3BxZJEbE"
      },
      "source": [
        "# ALL CONSTANTS\n",
        "\n",
        "VOCAB_PATH = '/content/drive/MyDrive/drama/resources/genre_one_hot_encoder_vocab.csv'\n",
        "GENRE_ONE_HOT_LOOKUP_PATH = '/content/drive/MyDrive/drama/resources/genre_one_hot_lookup.csv'\n",
        "GENRE_TRAINING_DATA_PATH = \"/content/drive/My Drive/drama/clean_fields.csv\"\n",
        "GENRE_COL = 'genre'\n",
        "NAME_COL = 'main_name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u5aDcPL0l1w"
      },
      "source": [
        "# train one hot encoder\n",
        "\n",
        "genre_one_hot = get_genre_one_hot_encoder_model(train=True, write_vocab=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP7_ksz70jte",
        "outputId": "0b830f95-8ede-4f80-84a4-5fe0a6879ca3"
      },
      "source": [
        "# infer on test data\n",
        "\n",
        "test_data = pd.DataFrame({'main_name': ['SoapOpera'],\n",
        "                          'genre': ['drama']})\n",
        "\n",
        "genre_one_hot.predict(test_data['genre'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20e3f91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMl5om7P3Xtt",
        "outputId": "be2019e5-2a7a-4329-bbad-ab079da21dae"
      },
      "source": [
        "# load encoder and infer\n",
        "\n",
        "genre_one_hot = get_genre_one_hot_encoder_model()\n",
        "\n",
        "genre_one_hot.predict(test_data['genre'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20db63e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhv8ZYGSBhbU"
      },
      "source": [
        "# Store one hot encodings of all known dramas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EcY0pCJAYF9"
      },
      "source": [
        "def store_genre_one_hot():\n",
        "  # load all data\n",
        "  all_data = load_genre_training_data(GENRE_TRAINING_DATA_PATH, keep_name_col=True)\n",
        "\n",
        "  # load vocab\n",
        "  vocab = read_genre_vocab(VOCAB_PATH)\n",
        "  vocab = ['OOV'] + vocab\n",
        "\n",
        "  # create one hot pd.DataFrame\n",
        "  all_data_genre_one_hot = pd.DataFrame(genre_one_hot.predict(all_data[GENRE_COL].values), index=all_data[NAME_COL], columns=vocab)\n",
        "\n",
        "  # TODO: save to file\n",
        "  all_data_genre_one_hot.to_csv(GENRE_ONE_HOT_LOOKUP_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gERS5jOKbAOt"
      },
      "source": [
        "# Calculate pairwise cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b1uhLBvIedD"
      },
      "source": [
        "def load_one_hot_vectors(lookup_path):\n",
        "  return pd.read_csv(lookup_path, index_col=NAME_COL)\n",
        "\n",
        "def lookup_genres_from_one_hot(genre_one_hot, vocab):\n",
        "  \"\"\"\n",
        "  Returns genre list from genre one hot encoded vector.\n",
        "  \"\"\"\n",
        "  return [x for (x, y) in zip(vocab, genre_one_hot) if y == 1]\n",
        "\n",
        "\n",
        "def _get_top_k(cosine_simil):\n",
        "  from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine_similarity\n",
        "  import numpy as np\n",
        "\n",
        "  closest_k = cosine_simil.argsort()[-k:]\n",
        "\n",
        "  # check for ties\n",
        "  cutoff_simil = cosine_simil[closest_k[0]]\n",
        "  all_indexes_above_cutoff = np.argwhere(cosine_simil >= cutoff_simil)\n",
        "  all_indexes_above_cutoff = all_indexes_above_cutoff.ravel()\n",
        "\n",
        "  # get random k if\n",
        "  if len(all_indexes_above_cutoff) > k:\n",
        "    np.random.seed(1)\n",
        "    return np.random.choice(all_indexes_above_cutoff, size=k, replace=False)  # wht if less then k?\n",
        "  else:\n",
        "    return all_indexes_above_cutoff\n",
        "\n",
        "\n",
        "def _print_info(request, selected_drama_names, vocab, one_hot_selected_dramas):\n",
        "  print(\"Genre of request:\", \n",
        "        lookup_genres_from_one_hot(request[0], vocab))\n",
        "  \n",
        "  for i in range(len(selected_drama_names)):\n",
        "    print(\"Drama\", i)\n",
        "    print(\"Name:\", selected_drama_names[i])\n",
        "    \n",
        "    selected_drama_genre_one_hot = one_hot_selected_dramas[i, :]\n",
        "    print(\"One hot encoding of genre: \", selected_drama_genre_one_hot)\n",
        "    print(\"Genre:\", \n",
        "          lookup_genres_from_one_hot(selected_drama_genre_one_hot, vocab))\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity_and_retrieve_top_k(request, all_data, k=3, debug=False, vocab=None):\n",
        "  drama_names = all_data.index\n",
        "  all_data = all_data.values\n",
        "\n",
        "  cosine_simil = sklearn_cosine_similarity(request, all_data)[0]\n",
        "  top_k_indices = _get_top_k(cosine_simil)\n",
        "  \n",
        "  if debug:\n",
        "    if vocab is None:\n",
        "      raise ValueError(\"Must pass vocab in debug mode.\")\n",
        "    # print info\n",
        "    selected_drama_names = drama_names[top_k_indices]\n",
        "    one_hot_selected_dramas = all_data[top_k_indices, :]\n",
        "\n",
        "    _print_info(request, selected_drama_names, vocab, one_hot_selected_dramas)\n",
        "  \n",
        "  # return names\n",
        "  return drama_names[top_k_indices].tolist()\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUWutUkDRQRj",
        "outputId": "728a52c5-8ec8-419a-ed94-e24bc7292359"
      },
      "source": [
        "request_data = pd.DataFrame({'main_name': ['SoapOpera'],\n",
        "                          'genre': ['drama family mystery']})\n",
        "\n",
        "# get one hot encoding of genre of request drama\n",
        "genre_one_hot_model = get_genre_one_hot_encoder_model()\n",
        "request_genre_one_hot = genre_one_hot_model.predict(request_data[GENRE_COL].values)\n",
        "\n",
        "# get top dramas\n",
        "all_data_genre_one_hot = load_one_hot_vectors(GENRE_ONE_HOT_LOOKUP_PATH)\n",
        "top_dramas = calculate_cosine_similarity_and_retrieve_top_k(request_genre_one_hot, \n",
        "                                                            all_data_genre_one_hot, \n",
        "                                                            debug=True,\n",
        "                                                            vocab=vocab)\n",
        "top_dramas\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb205d92730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Genre of request: ['drama', 'mystery', 'family']\n",
            "Drama 0\n",
            "Name: She Knows Everything\n",
            "One hot encoding of genre:  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Genre: ['drama', 'mystery']\n",
            "Drama 1\n",
            "Name: Blackout\n",
            "One hot encoding of genre:  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Genre: ['drama', 'mystery']\n",
            "Drama 2\n",
            "Name: My Unfamiliar Family\n",
            "One hot encoding of genre:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Genre: ['drama', 'family']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['She Knows Everything', 'Blackout', 'My Unfamiliar Family']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    }
  ]
}